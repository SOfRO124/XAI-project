{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "306c0ee9-6062-4d58-b028-536412acb5ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.10.4 (v3.10.4:9d38120e33, Mar 23 2022, 17:29:05) [Clang 13.0.0 (clang-1300.0.29.30)]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version) #should be <3.12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f924f184-8e1e-436a-942a-1e883cf16a94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-01 18:27:26.823617: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-01 18:27:38.180712: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF version 2.11.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd, numpy as np\n",
    "from pprint import pprint\n",
    "\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "from lime.lime_tabular import LimeTabularExplainer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "from transformers import *\n",
    "import tokenizers\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('TF version',tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4673197-989c-4ff3-8dc3-9d330cdf34d6",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c7420b30-cfc5-412b-b3ac-316f5b81cedd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file roBERTaFiles/config-roberta-base.json\n",
      "Model config RobertaConfig {\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": null,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"eos_token_ids\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": null,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.19.4\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "roBERTaFiles/pretrained-roberta-base.h5 is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo with `use_auth_token` or log in with `huggingface-cli login` and pass `use_auth_token=True`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRepositoryNotFoundError\u001b[0m                   Traceback (most recent call last)",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/transformers/modeling_tf_utils.py:1707\u001b[0m, in \u001b[0;36mTFPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   1705\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1706\u001b[0m     \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[0;32m-> 1707\u001b[0m     resolved_archive_file \u001b[38;5;241m=\u001b[39m \u001b[43mcached_path\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1708\u001b[0m \u001b[43m        \u001b[49m\u001b[43marchive_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1709\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1710\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1711\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1712\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1713\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1714\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_auth_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_auth_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1715\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1716\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1718\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m RepositoryNotFoundError:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/transformers/utils/hub.py:283\u001b[0m, in \u001b[0;36mcached_path\u001b[0;34m(url_or_filename, cache_dir, force_download, proxies, resume_download, user_agent, extract_compressed_file, force_extract, use_auth_token, local_files_only)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_remote_url(url_or_filename):\n\u001b[1;32m    282\u001b[0m     \u001b[38;5;66;03m# URL, so get it from the cache (downloading if necessary)\u001b[39;00m\n\u001b[0;32m--> 283\u001b[0m     output_path \u001b[38;5;241m=\u001b[39m \u001b[43mget_from_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl_or_filename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_auth_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_auth_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(url_or_filename):\n\u001b[1;32m    294\u001b[0m     \u001b[38;5;66;03m# File, and it exists.\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/transformers/utils/hub.py:494\u001b[0m, in \u001b[0;36mget_from_cache\u001b[0;34m(url, cache_dir, force_download, proxies, etag_timeout, resume_download, user_agent, use_auth_token, local_files_only)\u001b[0m\n\u001b[1;32m    493\u001b[0m r \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mhead(url, headers\u001b[38;5;241m=\u001b[39mheaders, allow_redirects\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, proxies\u001b[38;5;241m=\u001b[39mproxies, timeout\u001b[38;5;241m=\u001b[39metag_timeout)\n\u001b[0;32m--> 494\u001b[0m \u001b[43m_raise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    495\u001b[0m etag \u001b[38;5;241m=\u001b[39m r\u001b[38;5;241m.\u001b[39mheaders\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX-Linked-Etag\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m r\u001b[38;5;241m.\u001b[39mheaders\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mETag\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/transformers/utils/hub.py:416\u001b[0m, in \u001b[0;36m_raise_for_status\u001b[0;34m(response)\u001b[0m\n\u001b[1;32m    414\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m401\u001b[39m:\n\u001b[1;32m    415\u001b[0m     \u001b[38;5;66;03m# The repo was not found and the user is not Authenticated\u001b[39;00m\n\u001b[0;32m--> 416\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RepositoryNotFoundError(\n\u001b[1;32m    417\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m401 Client Error: Repository not found for url: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    418\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf the repo is private, make sure you are authenticated.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    419\u001b[0m     )\n\u001b[1;32m    421\u001b[0m response\u001b[38;5;241m.\u001b[39mraise_for_status()\n",
      "\u001b[0;31mRepositoryNotFoundError\u001b[0m: 401 Client Error: Repository not found for url: https://huggingface.co/roBERTaFiles/pretrained-roberta-base.h5/resolve/main/tf_model.h5. If the repo is private, make sure you are authenticated.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Input \u001b[0;32mIn [20]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m config \u001b[38;5;241m=\u001b[39m RobertaConfig\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mroBERTaFiles/config-roberta-base.json\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m bert_model \u001b[38;5;241m=\u001b[39m \u001b[43mTFRobertaModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mroBERTaFiles/pretrained-roberta-base.h5\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m bert_model\u001b[38;5;241m.\u001b[39msummary()\n\u001b[1;32m      4\u001b[0m new_model \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mload_model(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mv0-roberta-0l.h5\u001b[39m\u001b[38;5;124m'\u001b[39m,custom_objects\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTFRobertaModel\u001b[39m\u001b[38;5;124m\"\u001b[39m: bert_model})\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/transformers/modeling_tf_utils.py:1719\u001b[0m, in \u001b[0;36mTFPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   1707\u001b[0m     resolved_archive_file \u001b[38;5;241m=\u001b[39m cached_path(\n\u001b[1;32m   1708\u001b[0m         archive_file,\n\u001b[1;32m   1709\u001b[0m         cache_dir\u001b[38;5;241m=\u001b[39mcache_dir,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1715\u001b[0m         user_agent\u001b[38;5;241m=\u001b[39muser_agent,\n\u001b[1;32m   1716\u001b[0m     )\n\u001b[1;32m   1718\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m RepositoryNotFoundError:\n\u001b[0;32m-> 1719\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[1;32m   1720\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpretrained_model_name_or_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not a local folder and is not a valid model identifier \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1721\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlisted on \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://huggingface.co/models\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mIf this is a private repository, make sure to pass a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1722\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken having permission to this repo with `use_auth_token` or log in with `huggingface-cli \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1723\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogin` and pass `use_auth_token=True`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1724\u001b[0m     )\n\u001b[1;32m   1725\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m RevisionNotFoundError:\n\u001b[1;32m   1726\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[1;32m   1727\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrevision\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not a valid git identifier (branch name, tag name or commit id) that exists for \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1728\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthis model name. Check the model page at \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1729\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://huggingface.co/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpretrained_model_name_or_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m for available revisions.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1730\u001b[0m     )\n",
      "\u001b[0;31mOSError\u001b[0m: roBERTaFiles/pretrained-roberta-base.h5 is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo with `use_auth_token` or log in with `huggingface-cli login` and pass `use_auth_token=True`."
     ]
    }
   ],
   "source": [
    "config = RobertaConfig.from_pretrained('roBERTaFiles/config-roberta-base.json')\n",
    "bert_model = TFRobertaModel.from_pretrained('roBERTaFiles/pretrained-roberta-base.h5',config=config)\n",
    "bert_model.summary()\n",
    "new_model = tf.keras.models.load_model('v0-roberta-0l.h5',custom_objects={\"TFRobertaModel\": bert_model})\n",
    "\n",
    "# Show the model architecture\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3802d3c-f129-4596-9432-76037daedd3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([    0,    94,  1852,     9,     5,   183,  2054,   640, 17137,\n",
      "         405, 19017,     4,   175,    73,  4111,  5841,   298,     2,\n",
      "           2,  7974,     2,     1,     1,     1,     1,     1,     1,\n",
      "           1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "           1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "           1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "           1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "           1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "           1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "           1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "           1,     1,     1,     1,     1,     1], dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "PATH = 'roBERTaFiles'\n",
    "DISPLAY=1\n",
    "sentiment_id = {'positive': 1313, 'negative': 2430, 'neutral': 7974}\n",
    "test = pd.read_csv('tweet-sentiment-extraction/test.csv').fillna('')\n",
    "\n",
    "# tokenizer\n",
    "#def tokenizer(sentiment_id=sentiment_id, test = test):\n",
    "tokenizer = tokenizers.ByteLevelBPETokenizer(\n",
    "    vocab=PATH+'/vocab-roberta-base.json', \n",
    "    merges=PATH+'/merges-roberta-base.txt', \n",
    "    lowercase=True,\n",
    "    add_prefix_space=True\n",
    ")\n",
    "\n",
    "MAX_LEN = 96\n",
    "\n",
    "# test tweets\n",
    "ct = test.shape[0]\n",
    "input_ids_t = np.ones((ct,MAX_LEN),dtype='int32')\n",
    "attention_mask_t = np.zeros((ct,MAX_LEN),dtype='int32')\n",
    "token_type_ids_t = np.zeros((ct,MAX_LEN),dtype='int32')\n",
    "\n",
    "for k in range(test.shape[0]): \n",
    "    # INPUT_IDS\n",
    "    text1 = \" \"+\" \".join(test.loc[k,'text'].split())\n",
    "    enc = tokenizer.encode(text1)                \n",
    "    s_tok = sentiment_id[test.loc[k,'sentiment']]\n",
    "    input_ids_t[k,:len(enc.ids)+5] = [0] + enc.ids + [2,2] + [s_tok] + [2]\n",
    "    attention_mask_t[k,:len(enc.ids)+5] = 1\n",
    "\n",
    "pprint(input_ids_t[0])#[input_ids_t,attention_mask_t,token_type_ids_t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fdaded95-a946-43df-9745-e74a645e7b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(tokenizer()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1079e9f-f75d-49c9-98d4-0ec4383d5a82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111/111 [==============================] - 777s 7s/step\n"
     ]
    }
   ],
   "source": [
    "predictions = new_model.predict([input_ids_t,attention_mask_t,token_type_ids_t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3eb33508-2fba-484c-a415-83821149afb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from shap import DeepExplainer, force_plot, initjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9cb69fa-6296-4854-b519-17a6b16bb693",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# use KernelShap to get explaination\n",
    "#input =[input_ids_t,attention_mask_t,token_type_ids_t]\n",
    "#exp = DeepExplainer(new_model, input)\n",
    "#shap_values = exp.shap_values(input) #here instance_id\n",
    "# plot shapely values\n",
    "#force_plot(exp.expected_value, shap_values, X_test.iloc[instance_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2092d007-886b-4e6a-9bad-5fdfbc0febe7",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "oof_start = predictions[0]\n",
    "oof_end = predictions[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7adce6ed-0482-4c41-8aad-7cbe1dec8f0b",
   "metadata": {},
   "source": [
    "### LIME\n",
    "compare only with roberta sentiment part\n",
    "\n",
    "or with start/end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7408b617-4da6-4354-95c1-f07af39e3bea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last session of the day  http://twitpic.com/67ezh\n"
     ]
    }
   ],
   "source": [
    "print(test['text'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c845270a-9dc4-4e75-a6c3-13d04524919c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i</th>\n",
       "      <th>m</th>\n",
       "      <th>tt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0, 94, 1852, 9, 5, 183, 2054, 640, 17137, 405...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0, 1481, 260, 43673, 16, 67, 269, 3571, 36, 5...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0, 7306, 478, 4342, 261, 5150, 5378, 42134, 1...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0, 1372, 741, 1208, 328, 2, 2, 1313, 2, 1, 1,...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0, 2054, 640, 17137, 405, 19017, 4, 175, 73, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   i  m  \\\n",
       "0  [0, 94, 1852, 9, 5, 183, 2054, 640, 17137, 405...  0   \n",
       "1  [0, 1481, 260, 43673, 16, 67, 269, 3571, 36, 5...  0   \n",
       "2  [0, 7306, 478, 4342, 261, 5150, 5378, 42134, 1...  0   \n",
       "3  [0, 1372, 741, 1208, 328, 2, 2, 1313, 2, 1, 1,...  0   \n",
       "4  [0, 2054, 640, 17137, 405, 19017, 4, 175, 73, ...  0   \n",
       "\n",
       "                                                  tt  \n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_s = pd.read_csv('tweet-sentiment-extraction/test.csv')\n",
    "input_s.head()\n",
    "categorical_features = [i for i, col in enumerate(input_s) if np.unique(col).size < 10]\n",
    "\n",
    "input_t = pd.DataFrame({'i':input_ids_t.tolist(),'m':attention_mask_t.tolist(),'tt':token_type_ids_t.tolist()})\n",
    "input_t['m'] = [tmp.index(1) for tmp in input_t['m']]\n",
    "input_t[:]\n",
    "#print(input_t['m'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7b6b7f5a-718d-4c33-aa67-90908803da12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(use_idf=True)\n",
    "tfidf_id = tfidf.fit_transform(input_s['textID']) \n",
    "tfidf_t = tfidf.fit_transform(input_s['text']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6789bdc1-b8cd-421e-b1c8-9e2bba849998",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "pipeline = make_pipeline(tfidf, new_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f5c551ff-3906-442c-87bd-fb9c212d36d2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/engine/training.py\", line 2137, in predict_function  *\n        return step_function(self, iterator)\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/engine/training.py\", line 2123, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/engine/training.py\", line 2111, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/engine/training.py\", line 2079, in predict_step\n        return self(x, training=False)\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/var/folders/gm/65pg5ft92gl57s7lttz9b7dm0000gn/T/__autograph_generated_fileyes06hs0.py\", line 21, in tf__run_call_with_unpacked_inputs\n        retval_ = ag__.converted_call(ag__.ld(func), (ag__.ld(self),), dict(**ag__.ld(unpacked_inputs)), fscope)\n    File \"/var/folders/gm/65pg5ft92gl57s7lttz9b7dm0000gn/T/__autograph_generated_file74p8pb95.py\", line 30, in tf__call\n        outputs = ag__.converted_call(ag__.ld(self).roberta, (), dict(input_ids=ag__.ld(input_ids), attention_mask=ag__.ld(attention_mask), token_type_ids=ag__.ld(token_type_ids), position_ids=ag__.ld(position_ids), head_mask=ag__.ld(head_mask), inputs_embeds=ag__.ld(inputs_embeds), encoder_hidden_states=ag__.ld(encoder_hidden_states), encoder_attention_mask=ag__.ld(encoder_attention_mask), past_key_values=ag__.ld(past_key_values), use_cache=ag__.ld(use_cache), output_attentions=ag__.ld(output_attentions), output_hidden_states=ag__.ld(output_hidden_states), return_dict=ag__.ld(return_dict), training=ag__.ld(training)), fscope)\n    File \"/var/folders/gm/65pg5ft92gl57s7lttz9b7dm0000gn/T/__autograph_generated_fileyes06hs0.py\", line 21, in tf__run_call_with_unpacked_inputs\n        retval_ = ag__.converted_call(ag__.ld(func), (ag__.ld(self),), dict(**ag__.ld(unpacked_inputs)), fscope)\n    File \"/var/folders/gm/65pg5ft92gl57s7lttz9b7dm0000gn/T/__autograph_generated_file_igp1fjn.py\", line 75, in tf__call\n        (batch_size, seq_length) = ag__.ld(input_shape)\n\n    ValueError: Exception encountered when calling layer 'tf_roberta_model' (type TFRobertaModel).\n    \n    in user code:\n    \n        File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/transformers/modeling_tf_utils.py\", line 928, in run_call_with_unpacked_inputs  *\n            return func(self, **unpacked_inputs)\n        File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/transformers/models/roberta/modeling_tf_roberta.py\", line 959, in call  *\n            outputs = self.roberta(\n        File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler  **\n            raise e.with_traceback(filtered_tb) from None\n        File \"/var/folders/gm/65pg5ft92gl57s7lttz9b7dm0000gn/T/__autograph_generated_fileyes06hs0.py\", line 21, in tf__run_call_with_unpacked_inputs\n            retval_ = ag__.converted_call(ag__.ld(func), (ag__.ld(self),), dict(**ag__.ld(unpacked_inputs)), fscope)\n        File \"/var/folders/gm/65pg5ft92gl57s7lttz9b7dm0000gn/T/__autograph_generated_file_igp1fjn.py\", line 75, in tf__call\n            (batch_size, seq_length) = ag__.ld(input_shape)\n    \n        ValueError: Exception encountered when calling layer 'roberta' (type TFRobertaMainLayer).\n        \n        in user code:\n        \n            File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/transformers/modeling_tf_utils.py\", line 928, in run_call_with_unpacked_inputs  *\n                return func(self, **unpacked_inputs)\n            File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/transformers/models/roberta/modeling_tf_roberta.py\", line 641, in call  *\n                batch_size, seq_length = input_shape\n        \n            ValueError: not enough values to unpack (expected 2, got 1)\n        \n        \n        Call arguments received by layer 'roberta' (type TFRobertaMainLayer):\n          • self=tf.Tensor(shape=(None,), dtype=string)\n          • input_ids=None\n          • attention_mask=None\n          • token_type_ids=None\n          • position_ids=None\n          • head_mask=None\n          • inputs_embeds=None\n          • encoder_hidden_states=None\n          • encoder_attention_mask=None\n          • past_key_values=None\n          • use_cache=True\n          • output_attentions=False\n          • output_hidden_states=False\n          • return_dict=True\n          • training=False\n    \n    \n    Call arguments received by layer 'tf_roberta_model' (type TFRobertaModel):\n      • self=tf.Tensor(shape=(None,), dtype=string)\n      • input_ids=None\n      • attention_mask=None\n      • token_type_ids=None\n      • position_ids=None\n      • head_mask=None\n      • inputs_embeds=None\n      • encoder_hidden_states=None\n      • encoder_attention_mask=None\n      • past_key_values=None\n      • use_cache=None\n      • output_attentions=None\n      • output_hidden_states=None\n      • return_dict=None\n      • training=False\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [41]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m explainer \u001b[38;5;241m=\u001b[39m LimeTextExplainer(class_names \u001b[38;5;241m=\u001b[39m sentiment_id\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# (input_s.iloc[0]['textID'],input_s.iloc[0]['text'],input_s.iloc[0]['sentiment'])\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m exp \u001b[38;5;241m=\u001b[39m \u001b[43mexplainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexplain_instance\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_s\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mbert_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/lime/lime_text.py:413\u001b[0m, in \u001b[0;36mLimeTextExplainer.explain_instance\u001b[0;34m(self, text_instance, classifier_fn, labels, top_labels, num_features, num_samples, distance_metric, model_regressor)\u001b[0m\n\u001b[1;32m    406\u001b[0m indexed_string \u001b[38;5;241m=\u001b[39m (IndexedCharacters(\n\u001b[1;32m    407\u001b[0m     text_instance, bow\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbow, mask_string\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmask_string)\n\u001b[1;32m    408\u001b[0m                   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchar_level \u001b[38;5;28;01melse\u001b[39;00m\n\u001b[1;32m    409\u001b[0m                   IndexedString(text_instance, bow\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbow,\n\u001b[1;32m    410\u001b[0m                                 split_expression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplit_expression,\n\u001b[1;32m    411\u001b[0m                                 mask_string\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmask_string))\n\u001b[1;32m    412\u001b[0m domain_mapper \u001b[38;5;241m=\u001b[39m TextDomainMapper(indexed_string)\n\u001b[0;32m--> 413\u001b[0m data, yss, distances \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__data_labels_distances\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    414\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindexed_string\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclassifier_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistance_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdistance_metric\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    417\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_names \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mstr\u001b[39m(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(yss[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/lime/lime_text.py:482\u001b[0m, in \u001b[0;36mLimeTextExplainer.__data_labels_distances\u001b[0;34m(self, indexed_string, classifier_fn, num_samples, distance_metric)\u001b[0m\n\u001b[1;32m    480\u001b[0m     data[i, inactive] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    481\u001b[0m     inverse_data\u001b[38;5;241m.\u001b[39mappend(indexed_string\u001b[38;5;241m.\u001b[39minverse_removing(inactive))\n\u001b[0;32m--> 482\u001b[0m labels \u001b[38;5;241m=\u001b[39m \u001b[43mclassifier_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minverse_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    483\u001b[0m distances \u001b[38;5;241m=\u001b[39m distance_fn(sp\u001b[38;5;241m.\u001b[39msparse\u001b[38;5;241m.\u001b[39mcsr_matrix(data))\n\u001b[1;32m    484\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data, labels, distances\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/var/folders/gm/65pg5ft92gl57s7lttz9b7dm0000gn/T/__autograph_generated_file3_beekcq.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__predict_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/var/folders/gm/65pg5ft92gl57s7lttz9b7dm0000gn/T/__autograph_generated_fileyes06hs0.py:21\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__run_call_with_unpacked_inputs\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     20\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(func), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m),), \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mag__\u001b[38;5;241m.\u001b[39mld(unpacked_inputs)), fscope)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     23\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/var/folders/gm/65pg5ft92gl57s7lttz9b7dm0000gn/T/__autograph_generated_file74p8pb95.py:30\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, training)\u001b[0m\n\u001b[1;32m     28\u001b[0m do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     29\u001b[0m retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefinedReturnValue()\n\u001b[0;32m---> 30\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroberta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     32\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/var/folders/gm/65pg5ft92gl57s7lttz9b7dm0000gn/T/__autograph_generated_fileyes06hs0.py:21\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__run_call_with_unpacked_inputs\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     20\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(func), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m),), \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mag__\u001b[38;5;241m.\u001b[39mld(unpacked_inputs)), fscope)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     23\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/var/folders/gm/65pg5ft92gl57s7lttz9b7dm0000gn/T/__autograph_generated_file_igp1fjn.py:75\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, training)\u001b[0m\n\u001b[1;32m     73\u001b[0m input_shape \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefined(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_shape\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     74\u001b[0m ag__\u001b[38;5;241m.\u001b[39mif_stmt(ag__\u001b[38;5;241m.\u001b[39mand_(\u001b[38;5;28;01mlambda\u001b[39;00m : ag__\u001b[38;5;241m.\u001b[39mld(input_ids) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mlambda\u001b[39;00m : ag__\u001b[38;5;241m.\u001b[39mld(inputs_embeds) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m), if_body_3, else_body_3, get_state_3, set_state_3, (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_shape\u001b[39m\u001b[38;5;124m'\u001b[39m,), \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 75\u001b[0m (batch_size, seq_length) \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mld(input_shape)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_state_4\u001b[39m():\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (past_key_values, past_key_values_length)\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/engine/training.py\", line 2137, in predict_function  *\n        return step_function(self, iterator)\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/engine/training.py\", line 2123, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/engine/training.py\", line 2111, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/engine/training.py\", line 2079, in predict_step\n        return self(x, training=False)\n    File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/var/folders/gm/65pg5ft92gl57s7lttz9b7dm0000gn/T/__autograph_generated_fileyes06hs0.py\", line 21, in tf__run_call_with_unpacked_inputs\n        retval_ = ag__.converted_call(ag__.ld(func), (ag__.ld(self),), dict(**ag__.ld(unpacked_inputs)), fscope)\n    File \"/var/folders/gm/65pg5ft92gl57s7lttz9b7dm0000gn/T/__autograph_generated_file74p8pb95.py\", line 30, in tf__call\n        outputs = ag__.converted_call(ag__.ld(self).roberta, (), dict(input_ids=ag__.ld(input_ids), attention_mask=ag__.ld(attention_mask), token_type_ids=ag__.ld(token_type_ids), position_ids=ag__.ld(position_ids), head_mask=ag__.ld(head_mask), inputs_embeds=ag__.ld(inputs_embeds), encoder_hidden_states=ag__.ld(encoder_hidden_states), encoder_attention_mask=ag__.ld(encoder_attention_mask), past_key_values=ag__.ld(past_key_values), use_cache=ag__.ld(use_cache), output_attentions=ag__.ld(output_attentions), output_hidden_states=ag__.ld(output_hidden_states), return_dict=ag__.ld(return_dict), training=ag__.ld(training)), fscope)\n    File \"/var/folders/gm/65pg5ft92gl57s7lttz9b7dm0000gn/T/__autograph_generated_fileyes06hs0.py\", line 21, in tf__run_call_with_unpacked_inputs\n        retval_ = ag__.converted_call(ag__.ld(func), (ag__.ld(self),), dict(**ag__.ld(unpacked_inputs)), fscope)\n    File \"/var/folders/gm/65pg5ft92gl57s7lttz9b7dm0000gn/T/__autograph_generated_file_igp1fjn.py\", line 75, in tf__call\n        (batch_size, seq_length) = ag__.ld(input_shape)\n\n    ValueError: Exception encountered when calling layer 'tf_roberta_model' (type TFRobertaModel).\n    \n    in user code:\n    \n        File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/transformers/modeling_tf_utils.py\", line 928, in run_call_with_unpacked_inputs  *\n            return func(self, **unpacked_inputs)\n        File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/transformers/models/roberta/modeling_tf_roberta.py\", line 959, in call  *\n            outputs = self.roberta(\n        File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler  **\n            raise e.with_traceback(filtered_tb) from None\n        File \"/var/folders/gm/65pg5ft92gl57s7lttz9b7dm0000gn/T/__autograph_generated_fileyes06hs0.py\", line 21, in tf__run_call_with_unpacked_inputs\n            retval_ = ag__.converted_call(ag__.ld(func), (ag__.ld(self),), dict(**ag__.ld(unpacked_inputs)), fscope)\n        File \"/var/folders/gm/65pg5ft92gl57s7lttz9b7dm0000gn/T/__autograph_generated_file_igp1fjn.py\", line 75, in tf__call\n            (batch_size, seq_length) = ag__.ld(input_shape)\n    \n        ValueError: Exception encountered when calling layer 'roberta' (type TFRobertaMainLayer).\n        \n        in user code:\n        \n            File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/transformers/modeling_tf_utils.py\", line 928, in run_call_with_unpacked_inputs  *\n                return func(self, **unpacked_inputs)\n            File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/transformers/models/roberta/modeling_tf_roberta.py\", line 641, in call  *\n                batch_size, seq_length = input_shape\n        \n            ValueError: not enough values to unpack (expected 2, got 1)\n        \n        \n        Call arguments received by layer 'roberta' (type TFRobertaMainLayer):\n          • self=tf.Tensor(shape=(None,), dtype=string)\n          • input_ids=None\n          • attention_mask=None\n          • token_type_ids=None\n          • position_ids=None\n          • head_mask=None\n          • inputs_embeds=None\n          • encoder_hidden_states=None\n          • encoder_attention_mask=None\n          • past_key_values=None\n          • use_cache=True\n          • output_attentions=False\n          • output_hidden_states=False\n          • return_dict=True\n          • training=False\n    \n    \n    Call arguments received by layer 'tf_roberta_model' (type TFRobertaModel):\n      • self=tf.Tensor(shape=(None,), dtype=string)\n      • input_ids=None\n      • attention_mask=None\n      • token_type_ids=None\n      • position_ids=None\n      • head_mask=None\n      • inputs_embeds=None\n      • encoder_hidden_states=None\n      • encoder_attention_mask=None\n      • past_key_values=None\n      • use_cache=None\n      • output_attentions=None\n      • output_hidden_states=None\n      • return_dict=None\n      • training=False\n"
     ]
    }
   ],
   "source": [
    "explainer = LimeTextExplainer(class_names = sentiment_id.keys())\n",
    "# (input_s.iloc[0]['textID'],input_s.iloc[0]['text'],input_s.iloc[0]['sentiment'])\n",
    "exp = explainer.explain_instance(input_s.iloc[0]['text'],\n",
    "                                 bert_model.predict, num_features=3 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9c1ff079-1dd5-4532-8e80-c7755008632c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: float() argument must be a string or a real number, not 'list'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [45]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m explainer \u001b[38;5;241m=\u001b[39m \u001b[43mLimeTabularExplainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_t\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mclass_names\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msentiment_id\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mtraining_labels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minput_t\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mcategorical_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcategorical_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mdiscretizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mentropy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m exp \u001b[38;5;241m=\u001b[39m explainer\u001b[38;5;241m.\u001b[39mexplain_instance(input_s\u001b[38;5;241m.\u001b[39miloc[[\u001b[38;5;241m0\u001b[39m]],new_model\u001b[38;5;241m.\u001b[39mpredict, num_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m )\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m#exp.show_in_notebook(text=False)\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/lime/lime_tabular.py:258\u001b[0m, in \u001b[0;36mLimeTabularExplainer.__init__\u001b[0;34m(self, training_data, mode, training_labels, feature_names, categorical_features, categorical_names, kernel_width, kernel, verbose, class_names, feature_selection, discretize_continuous, discretizer, sample_around_instance, random_state, training_data_stats)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;66;03m# Though set has no role to play if training data stats are provided\u001b[39;00m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler \u001b[38;5;241m=\u001b[39m sklearn\u001b[38;5;241m.\u001b[39mpreprocessing\u001b[38;5;241m.\u001b[39mStandardScaler(with_mean\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m--> 258\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_values \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_frequencies \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:809\u001b[0m, in \u001b[0;36mStandardScaler.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    807\u001b[0m \u001b[38;5;66;03m# Reset internal state before fitting\u001b[39;00m\n\u001b[1;32m    808\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[0;32m--> 809\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpartial_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:844\u001b[0m, in \u001b[0;36mStandardScaler.partial_fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    812\u001b[0m \u001b[38;5;124;03m\"\"\"Online computation of mean and std on X for later scaling.\u001b[39;00m\n\u001b[1;32m    813\u001b[0m \n\u001b[1;32m    814\u001b[0m \u001b[38;5;124;03mAll of X is processed as a single batch. This is intended for cases\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    841\u001b[0m \u001b[38;5;124;03m    Fitted scaler.\u001b[39;00m\n\u001b[1;32m    842\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    843\u001b[0m first_call \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_samples_seen_\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 844\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    845\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    846\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    847\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFLOAT_DTYPES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    848\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    849\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfirst_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    850\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    851\u001b[0m n_features \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    853\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/base.py:577\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    575\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation should be done on X, y or both.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    576\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> 577\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    578\u001b[0m     out \u001b[38;5;241m=\u001b[39m X\n\u001b[1;32m    579\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/utils/validation.py:856\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    854\u001b[0m         array \u001b[38;5;241m=\u001b[39m array\u001b[38;5;241m.\u001b[39mastype(dtype, casting\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munsafe\u001b[39m\u001b[38;5;124m\"\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    855\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 856\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[1;32m    858\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    859\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[1;32m    860\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "explainer = LimeTabularExplainer(np.array(input_t),class_names = sentiment_id.keys(),\n",
    "                                 training_labels = input_t['tt'],\n",
    "                                 categorical_features=categorical_features, \n",
    "                                 discretizer= 'entropy')\n",
    "\n",
    "exp = explainer.explain_instance(input_s.iloc[[0]],new_model.predict, num_features=3 )\n",
    "\n",
    "#exp.show_in_notebook(text=False)\n",
    "\n",
    "lime_df = pd.DataFrame(exp.as_list(),columns=['Feature','Contribution'])\n",
    "lime_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe8eee4-e59f-4826-8b34-9afd7f0215d9",
   "metadata": {},
   "source": [
    "### TCAV\n",
    "\n",
    "- first create lexicon for pos/neg/neutral sentiments\n",
    "- then use TCAV (captum) for projection on sentiments (concepts), probably after roBERTa layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3df6963-1c4b-454b-a93d-1279a5f80b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchtext\n",
    "from torchtext import vocab\n",
    "from torchtext.datasets import LanguageModelingDataset\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, IterableDataset\n",
    "\n",
    "import spacy\n",
    "import en_core_web_sm\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "#.... Captum imports..................\n",
    "from captum.concept import TCAV\n",
    "from captum.concept import Concept\n",
    "from captum.concept._utils.common import concepts_to_str\n",
    "from captum.concept._utils.data_iterator import dataset_to_dataloader, CustomIterableDataset\n",
    "\n",
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed8dcf0-2ac0-4d10-8972-363dc77a8f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load VADER (https://github.com/cjhutto/vaderSentiment?tab=readme-ov-file#resources-and-dataset-descriptions) lexicon\n",
    "lexicon = pd.read_csv('tweet-sentiment-extraction/vader_lexicon.txt', sep = \"\\t\", header = None)\n",
    "\n",
    "# separate pos (>1), neg (<-1&<0), neu(>-1 & <1) based on polarity-scores (column 1)\n",
    "def convert_labels(elem):\n",
    "    if elem > 1.0:\n",
    "        return 'positive'\n",
    "    elif elem > -1.0 and elem < 1.0:\n",
    "        return 'neutral'\n",
    "    else:\n",
    "        return 'negative'\n",
    "            \n",
    "\n",
    "lexicon[1] = lexicon[1].apply(lambda x: convert_labels(x))\n",
    "\n",
    "# create lexicon files for each sentiment\n",
    "lexicon = lexicon.drop(columns= [2,3])\n",
    "\n",
    "df_pos = lexicon[lexicon[1] == 'positive']\n",
    "df_neg = lexicon[lexicon[1] == 'negative']\n",
    "df_neu = lexicon[lexicon[1] == 'neutral']\n",
    "\n",
    "df_pos.to_csv('tweet-sentiment-extraction/positive.csv', index=False)\n",
    "df_neg.to_csv('tweet-sentiment-extraction/negative.csv', index=False)\n",
    "df_neu.to_csv('tweet-sentiment-extraction/neutral.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a8d314-c100-4cf8-b341-f181ef062264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make data field and load data\n",
    "def spacy_tok(x):\n",
    "    return [tok.text for tok in nlp.tokenizer(x)]\n",
    "\n",
    "TEXT = torchtext.data.Field(lower=True, tokenizer_language='en_core_web_sm', tokenize = spacy_tok)\n",
    "Label = torchtext.data.LabelField(dtype = torch.float)\n",
    "\n",
    "ds_pos = LanguageModelingDataset(\"tweet-sentiment-extraction/positive.csv\", TEXT)\n",
    "ds_neut = LanguageModelingDataset(\"tweet-sentiment-extraction/neutral.csv\", TEXT)\n",
    "ds_neg = LanguageModelingDataset(\"tweet-sentiment-extraction/negative.csv\", TEXT)\n",
    "\n",
    "TEXT.build_vocab(ds_pos,ds_neut,ds_neg)\n",
    "\n",
    "# load glove\n",
    "MAX_VOCAB_SIZE = 25_000\n",
    "loaded_vectors= torchtext.vocab.Vectors('tweet-sentiment-extraction/glove.6B.50d.txt')\n",
    "\n",
    "#TEXT.build_vocab(train, vectors=loaded_vectors, max_size=len(loaded_vectors.stoi))\n",
    "TEXT.vocab.set_vectors(stoi=loaded_vectors.stoi, vectors=loaded_vectors.vectors, dim=loaded_vectors.dim)\n",
    "print('Vocabulary Size: ', len(TEXT.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168cf193-e58c-41ea-98e7-b27b03a63afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tensor_from_filename(filename):\n",
    "    ds = torchtext.data.TabularDataset(path=filename,\n",
    "                                       fields=[('text', torchtext.data.Field()),\n",
    "                                               ('label', torchtext.data.Field())],\n",
    "                                       format='csv')\n",
    "    const_len = 7\n",
    "    for concept in ds:\n",
    "        concept.text = concept.text[:const_len]\n",
    "        concept.text += ['pad'] * max(0, const_len - len(concept.text))\n",
    "        text_indices = torch.tensor([TEXT.vocab.stoi[t] for t in concept.text], device=device)\n",
    "        yield text_indices\n",
    "        \n",
    "        \n",
    "def assemble_concept(name, id, concepts_path):\n",
    "    dataset = CustomIterableDataset(get_tensor_from_filename, concepts_path)\n",
    "    concept_iter = dataset_to_dataloader(dataset, batch_size=1)\n",
    "    return Concept(id=id, name=name, data_iter=concept_iter)\n",
    "\n",
    "\n",
    "def print_concept_sample(concept_iter):\n",
    "    cnt = 0\n",
    "    max_print = 10\n",
    "    item = next(concept_iter)\n",
    "    while cnt < max_print and item is not None:\n",
    "        print(' '.join([TEXT.vocab.itos[item_elem] for item_elem in item[0]]))\n",
    "        item = next(concept_iter)\n",
    "        cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4e639c-9630-4ba1-90ee-5ba7cb6abeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create concepts: match glove embeddings to words in lexicon\n",
    "neut = assemble_concept('neutral', 0, concepts_path=\"tweet-sentiment-extraction/neutral.csv\")\n",
    "pos = assemble_concept('positive', 1, concepts_path=\"tweet-sentiment-extraction/positive.csv\")\n",
    "neg = assemble_concept('negative', 2, concepts_path=\"tweet-sentiment-extraction/negative.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e80700-12dd-494c-acbd-734d85ff38fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_concept_sample(iter(pos.data_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956251ec-a873-426c-abbe-c3b31a987b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create multiple neutral concepts to test \n",
    "# repeat with neg and pos\n",
    "neutral_concept = assemble_concept('neutral', 0, concepts_path=\"data/tcav/text-sensitivity/neutral.csv\")\n",
    "neutral_concept4 = assemble_concept('neutral4', 3, concepts_path=\"data/tcav/text-sensitivity/neutral4.csv\")\n",
    "neutral_concept5 = assemble_concept('neutral5', 4, concepts_path=\"data/tcav/text-sensitivity/neutral5.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a4585b-8eaa-4224-b1e8-32f294ac3c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assemble sets to compare\n",
    "# repeat with diff layers\n",
    "# TCAV trains a model for each pair, and estimates tcav scores for each experimental set in given input layers.\n",
    "# score indicates the importance of a concept in a given layer (high = inportant)\n",
    "experimental_sets=[[pos, neut],\n",
    "                  [pos, neg]]\n",
    "\n",
    "tcav = TCAV(new_model, layers=['tf_roberta_model_1', 'conv1d'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048061a5-9e4e-4a67-b38c-22566168b293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert concepts to tensors\n",
    "def covert_text_to_tensor(input_texts):\n",
    "    input_tensors = []\n",
    "    for input_text in input_texts:\n",
    "        input_tensor = torch.tensor([TEXT.vocab.stoi[tok.text] for \\\n",
    "                                     tok in nlp.tokenizer(input_text)], device=device).unsqueeze(0)\n",
    "        input_tensors.append(input_tensor)\n",
    "    return torch.cat(input_tensors)\n",
    "\n",
    "# show tcav scores \n",
    "def extract_scores(interpretations, layer_name, score_type, idx):\n",
    "    return [interpretations[key][layer_name][score_type][idx].item() for key in interpretations.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e0d0b1-71cd-4b32-8dc9-b7ebfe2e53c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test tcav \n",
    "pos_input_texts = [\"It was a fantastic play ! pad\", \"A terrific film so far ! pad\", \"We loved that show ! pad pad\"]\n",
    "pos_input_text_indices = covert_text_to_tensor(pos_input_texts)\n",
    "\n",
    "positive_interpretations = tcav.interpret(pos_input_text_indices, experimental_sets=experimental_sets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4002f362-20c4-450d-b66b-c9719e19ff32",
   "metadata": {},
   "source": [
    "#### visualize tcav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa41c038-70f5-43d4-9467-31832135722e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_float(f):\n",
    "    return float('{:.3f}'.format(f) if abs(f) >= 0.0005 else '{:.3e}'.format(f))\n",
    "\n",
    "def plot_tcav_scores(experimental_sets, tcav_scores, layers = ['convs.2'], score_type='sign_count'):\n",
    "    fig, ax = plt.subplots(1, len(experimental_sets), figsize = (25, 7))\n",
    "\n",
    "    barWidth = 1 / (len(experimental_sets[0]) + 1)\n",
    "\n",
    "    for idx_es, concepts in enumerate(experimental_sets):\n",
    "        concepts = experimental_sets[idx_es]\n",
    "        concepts_key = concepts_to_str(concepts)\n",
    "        \n",
    "        layers = tcav_scores[concepts_key].keys()\n",
    "        pos = [np.arange(len(layers))]\n",
    "        for i in range(1, len(concepts)):\n",
    "            pos.append([(x + barWidth) for x in pos[i-1]])\n",
    "        _ax = (ax[idx_es] if len(experimental_sets) > 1 else ax)\n",
    "        for i in range(len(concepts)):\n",
    "            val = [format_float(scores[score_type][i]) for layer, scores in tcav_scores[concepts_key].items()]\n",
    "            _ax.bar(pos[i], val, width=barWidth, edgecolor='white', label=concepts[i].name)\n",
    "\n",
    "        # Add xticks on the middle of the group bars\n",
    "        _ax.set_xlabel('Set {}'.format(str(idx_es)), fontweight='bold', fontsize=16)\n",
    "        _ax.set_xticks([r + 0.3 * barWidth for r in range(len(layers))])\n",
    "        _ax.set_xticklabels(layers, fontsize=16)\n",
    "\n",
    "        # Create legend & Show graphic\n",
    "        _ax.legend(fontsize=16)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd33da9-0c00-404c-8059-6664c8672f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change inputs!!\n",
    "plot_tcav_scores(experimental_sets, positive_interpretations, ['tf_roberta_model_1', 'conv1d'], score_type='sign_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4412f4-16e8-49e9-88db-efd31e112c43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
