{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if os.getcwd().split('/')[-1] != 'tcav':\n",
    "    print(os.getcwd())\n",
    "    os.chdir('../')\n",
    "    os.chdir('../')\n",
    "    os.chdir('../')    \n",
    "    print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tcav.utils import create_session\n",
    "from tensorflow.io import gfile\n",
    "from tcav.model import ModelWrapper, KerasModelWrapper\n",
    "from tcav.tcav_examples.discrete.kdd99_activation_generator import KDD99DiscreteActivationGenerator\n",
    "from tcav.tcav_examples.discrete.kdd99_model_wrapper import KDD99KerasModelWrapper\n",
    "import tensorflow as tf\n",
    "from transformers import TFRobertaModel\n",
    "from tcav.activation_generator import ActivationGeneratorBase\n",
    "import tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make source directory, \n",
    "source_dir = \"c://Users//daoha//Downloads//explainableAI//project//tcav//\"\n",
    "working_dir = source_dir\n",
    "acts_dir = os.path.join(working_dir, \"activations\")\n",
    "gfile.makedirs(acts_dir)\n",
    "cav_dir = os.path.join(working_dir, \"cav\")\n",
    "gfile.makedirs(cav_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 96\n",
    "PATH = 'c://Users//daoha//Downloads//explainableAI//project//tcav//roBERTaFiles//'\n",
    "\n",
    "tokenizer = tokenizers.ByteLevelBPETokenizer(\n",
    "    vocab=PATH+'vocab-roberta-base.json',\n",
    "    merges=PATH+'merges-roberta-base.txt',\n",
    "    lowercase=True,\n",
    "    add_prefix_space=True\n",
    ")\n",
    "\n",
    "sentiment_id = {'positive': 1313, 'negative': 2430, 'neutral': 7974}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentModelWrapper(ModelWrapper):\n",
    "    def __init__(self, sess, model_path, custom_objects=None):\n",
    "        self.sess = sess\n",
    "        super(SentimentModelWrapper, self).__init__()\n",
    "        self.import_keras_model(model_path, custom_objects=custom_objects)\n",
    "        self.optimiezer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "        \n",
    "        # Using SparseCategoricalCrossEntropy here\n",
    "        self.y_input = tf.compat.v1.placeholder(tf.int64, shape=[None])\n",
    "        self.y_true = tf.one_hot(self.y_input, depth=96)\n",
    "        self.loss = self.model.loss_functions[0](self.y_true, self.model.outputs[0])\n",
    "        self._make_gradient_tensors()\n",
    "\n",
    "    def import_keras_model(self, model_path, custom_objects=None):\n",
    "        \"Load the model and fetch input/output tensors.\"\n",
    "        self.ends = {}\n",
    "        self.model = tf.keras.models.load_model(model_path, custom_objects=custom_objects)\n",
    "        self.get_bottleneck_tensors()\n",
    "        self.get_inputs_and_outputs_and_ends()\n",
    "\n",
    "    def get_bottleneck_tensors(self):\n",
    "        self.bottleneck_tensors = {}\n",
    "        bottleneck_layers = ['pooler_output', 'conv1d', 'conv1d_1']\n",
    "        for layer in bottleneck_layers:\n",
    "            if layer == 'pooler_output':\n",
    "                pooler_layer = self.model.get_layer('tf_roberta_model')\n",
    "                self.bottleneck_tensors[layer] = pooler_layer.output.pooler_output\n",
    "                print(type(self.bottleneck_tensors[layer]))\n",
    "            else:\n",
    "                self.bottleneck_tensors[layer] = self.model.get_layer(layer).output\n",
    "                print(type(self.bottleneck_tensors[layer]))\n",
    "\n",
    "    def get_inputs_and_outputs_and_ends(self):\n",
    "        \"Fetch input and output tensors.\"\n",
    "        self.ends['input'] = self.model.inputs[0]\n",
    "        self.ends['prediction'] = self.model.outputs[0]\n",
    "\n",
    "    def _make_gradient_tensors(self):\n",
    "        \"\"\"Makes gradient tensors for all bottleneck tensors.\"\"\"\n",
    "        print(self.bottleneck_tensors)\n",
    "        self.bottlenecks_gradients = {}\n",
    "        for bn_name, bn_tensor in self.bottleneck_tensors.items():\n",
    "            if bn_tensor is not None:\n",
    "                gradient_tensor = tf.gradients(\n",
    "                    ys=self.loss,\n",
    "                    xs=bn_tensor\n",
    "                )[0]\n",
    "                self.bottlenecks_gradients[bn_name] = gradient_tensor\n",
    "            else:\n",
    "                raise ValueError(f\"{bn_name} tensor is None. Check model architecture.\")\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tcav.activation_generator import ActivationGeneratorBase\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class SentimentActivationGenerator(ActivationGeneratorBase):\n",
    "    def __init__(self, model, tokenizer, sentiment_id, source_dir, acts_dir, max_examples=500):\n",
    "        super(SentimentActivationGenerator, self).__init__(model, acts_dir, max_examples)\n",
    "        self.source_dir = source_dir\n",
    "        self.tokenizer = tokenizer\n",
    "        self.sentiment_id = sentiment_id\n",
    "\n",
    "    def get_examples_for_concept(self, concept):\n",
    "        concept_folder = os.path.join(self.source_dir, concept)\n",
    "        concept_file = os.path.join(concept_folder, concept + '.csv')\n",
    "        df = pd.read_csv(concept_file)\n",
    "        examples = self.transform_data(df)\n",
    "        return examples\n",
    "\n",
    "    def transform_data(self, examples):\n",
    "        # Initialize the input arrays\n",
    "        input_ids = np.ones((len(examples), MAX_LEN), dtype='int32')\n",
    "        attention_mask = np.zeros((len(examples), MAX_LEN), dtype='int32')\n",
    "        token_type_ids_t = np.zeros((len(examples), MAX_LEN), dtype='int32') \n",
    "\n",
    "        # Tokenize the examples and set up the input arrays\n",
    "        for k in range(len(examples)):\n",
    "            text = \" \" + \" \".join(examples.loc[k,'text'].split())\n",
    "            enc = self.tokenizer.encode(text)\n",
    "            s_tok = self.sentiment_id[examples.loc[k,'sentiment']]\n",
    "            input_ids[k, :len(enc.ids)+5] = [0] + enc.ids + [2, 2] + [s_tok] + [2]\n",
    "            attention_mask[k, :len(enc.ids)+5] = 1\n",
    "\n",
    "        return [input_ids, attention_mask, token_type_ids_t]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.path.join(source_dir, \"v0-roberta-0.h5\")\n",
    "sess = create_session()\n",
    "custom_objects = {'TFRobertaModel': TFRobertaModel}\n",
    "\n",
    "mymodel = SentimentModelWrapper(sess, model_path, custom_objects=custom_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create activation generator\n",
    "act_gen = SentimentActivationGenerator(model=mymodel, tokenizer=tokenizer, sentiment_id=sentiment_id, source_dir=source_dir, acts_dir=acts_dir, max_examples=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tcav.utils import create_session\n",
    "import tcav.utils_plot as utils_plot # utils_plot requires matplotlib\n",
    "from tcav.tcav import TCAV\n",
    "import absl\n",
    "absl.logging.set_verbosity(0)\n",
    "\n",
    "target = \"positive\"\n",
    "bottlenecks = [\"conv1d\", \"conv1d_1\"]\n",
    "concepts = [\"positive_words\", \"neutral_words\"]\n",
    "alphas = [0.01]\n",
    "\n",
    "\n",
    "\n",
    "my_tcav = TCAV(create_session,\n",
    "                   target,\n",
    "                   concepts,\n",
    "                   bottlenecks,\n",
    "                   act_gen,\n",
    "                   alphas,\n",
    "                   cav_dir=cav_dir,\n",
    "                   num_random_exp=5)\n",
    "\n",
    "\n",
    "results = my_tcav.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
